{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c8bafe6d",
   "metadata": {},
   "source": [
    "## **s1reader + ISCE3 + dolphin**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdba201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import glob\n",
    "from pathlib import Path\n",
    "# Insert local scripts directory to the system path\n",
    "notebook_dir = Path().resolve()\n",
    "scripts_dir = str(notebook_dir.parent / 'scripts')\n",
    "if scripts_dir not in sys.path:\n",
    "    sys.path.insert(0, scripts_dir)\n",
    "\n",
    "\n",
    "# Input workspace and meta data location\n",
    "WORKSPACE = \"/mnt/e/InSAR/Stuttgart/ISCE3\"          # The workspace prepared for ISCE2 processing\n",
    "RAW_LOCATION = \"/mnt/e/InSAR/Stuttgart/RAW\"         # The location of Sentinel-1 TOPS data\n",
    "LOCAL_DEM_DIR = \"/mnt/e/DEM/SRTMGL1/\"               # The location which you stored all the local SRTM GL1 DEM tiles\n",
    "\n",
    "# Then automatically set up the orbit and auxliary calibration files directory\n",
    "ORBIT_DIR = os.path.join(WORKSPACE, \"ORB\")\n",
    "os.makedirs(ORBIT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4064b8",
   "metadata": {},
   "source": [
    "The following steps: Download orbit data -> Download and stitch dem -> Generate DEM config -> Run stack processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68e482e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 15 SAFE files\n"
     ]
    }
   ],
   "source": [
    "# Locate all SAFE files in the directory\n",
    "safe_files = glob.glob(os.path.join(RAW_LOCATION, 'S1*_IW_SLC*'))\n",
    "if not safe_files:\n",
    "    print(f\"No SAFE files found in directory: {RAW_LOCATION}\")\n",
    "\n",
    "print(f\"Found {len(safe_files)} SAFE files\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6027d57f",
   "metadata": {},
   "source": [
    "<b> 1. Download DEM </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7cbddc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10955 orbit files.\n",
      "Start downloading orbit files from ASF...\n",
      "* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */\n",
      "\n",
      "Processing: S1A_IW_SLC__1SDV_20240103T053454_20240103T053522_051938_06467F_A0C6.zip\n",
      "  Orbit file already exists: S1A_OPER_AUX_POEORB_OPOD_20240123T070858_V20240102T225942_20240104T005942.EOF\n",
      "* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */\n",
      "\n",
      "Processing: S1A_IW_SLC__1SDV_20240115T053454_20240115T053522_052113_064C75_0023.zip\n",
      "  Orbit file already exists: S1A_OPER_AUX_POEORB_OPOD_20240204T070755_V20240114T225942_20240116T005942.EOF\n",
      "* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */\n",
      "\n",
      "Processing: S1A_IW_SLC__1SDV_20240127T053454_20240127T053522_052288_065258_FDD9.zip\n",
      "  Orbit file already exists: S1A_OPER_AUX_POEORB_OPOD_20240216T070746_V20240126T225942_20240128T005942.EOF\n",
      "* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */\n",
      "\n",
      "Processing: S1A_IW_SLC__1SDV_20240208T053453_20240208T053521_052463_065842_70F5.zip\n",
      "  Orbit file already exists: S1A_OPER_AUX_POEORB_OPOD_20240228T070732_V20240207T225942_20240209T005942.EOF\n",
      "* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */\n",
      "\n",
      "Processing: S1A_IW_SLC__1SDV_20240220T053453_20240220T053521_052638_065E32_9C91.zip\n",
      "  Orbit file already exists: S1A_OPER_AUX_POEORB_OPOD_20240311T070733_V20240219T225942_20240221T005942.EOF\n",
      "* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */\n",
      "\n",
      "Processing: S1A_IW_SLC__1SDV_20240303T053453_20240303T053521_052813_06642D_F05E.zip\n",
      "  Orbit file already exists: S1A_OPER_AUX_POEORB_OPOD_20240323T070738_V20240302T225942_20240304T005942.EOF\n",
      "* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */\n",
      "\n",
      "Processing: S1A_IW_SLC__1SDV_20240315T053453_20240315T053521_052988_066A24_3803.zip\n",
      "  Orbit file already exists: S1A_OPER_AUX_POEORB_OPOD_20240404T070808_V20240314T225942_20240316T005942.EOF\n",
      "* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */\n",
      "\n",
      "Processing: S1A_IW_SLC__1SDV_20240327T053453_20240327T053521_053163_0670D9_F554.zip\n",
      "  Orbit file already exists: S1A_OPER_AUX_POEORB_OPOD_20240416T070801_V20240326T225942_20240328T005942.EOF\n",
      "* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */\n",
      "\n",
      "Processing: S1A_IW_SLC__1SDV_20240408T053454_20240408T053522_053338_0677A4_058B.zip\n",
      "  Orbit file already exists: S1A_OPER_AUX_POEORB_OPOD_20240428T070804_V20240407T225942_20240409T005942.EOF\n",
      "* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */\n",
      "\n",
      "Processing: S1A_IW_SLC__1SDV_20240420T053454_20240420T053522_053513_067E8C_31F6.zip\n",
      "  Orbit file already exists: S1A_OPER_AUX_POEORB_OPOD_20240510T070752_V20240419T225942_20240421T005942.EOF\n",
      "* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */\n",
      "\n",
      "Processing: S1A_IW_SLC__1SDV_20240502T053455_20240502T053523_053688_06856B_CA9B.zip\n",
      "  Orbit file already exists: S1A_OPER_AUX_POEORB_OPOD_20240522T070731_V20240501T225942_20240503T005942.EOF\n",
      "* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */\n",
      "\n",
      "Processing: S1A_IW_SLC__1SDV_20240514T053454_20240514T053522_053863_068BDF_B528.zip\n",
      "  Orbit file already exists: S1A_OPER_AUX_POEORB_OPOD_20240603T070839_V20240513T225942_20240515T005942.EOF\n",
      "* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */\n",
      "\n",
      "Processing: S1A_IW_SLC__1SDV_20240526T053455_20240526T053523_054038_0691E7_F2AC.zip\n",
      "  Orbit file already exists: S1A_OPER_AUX_POEORB_OPOD_20240615T070800_V20240525T225942_20240527T005942.EOF\n",
      "* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */\n",
      "\n",
      "Processing: S1A_IW_SLC__1SDV_20240607T053454_20240607T053522_054213_0697F4_0514.zip\n",
      "  Orbit file already exists: S1A_OPER_AUX_POEORB_OPOD_20240627T070839_V20240606T225942_20240608T005942.EOF\n",
      "* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */\n",
      "\n",
      "Processing: S1A_IW_SLC__1SDV_20240619T053453_20240619T053521_054388_069E03_567D.zip\n",
      "  Orbit file already exists: S1A_OPER_AUX_POEORB_OPOD_20240709T070826_V20240618T225942_20240620T005942.EOF\n",
      "* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */\n",
      "\n",
      "Finished downloading orbit files.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from urllib3.util.retry import Retry\n",
    "from requests.adapters import HTTPAdapter\n",
    "\n",
    "def _get_orbit_list() -> list[str]:\n",
    "    \"\"\"\n",
    "    从 ASF（Alaska Satellite Facility）服务器获取 Sentinel-1 卫星轨道文件列表。\n",
    "    \n",
    "    该函数从 ASF 的轨道文件存储库获取所有可用的精密轨道文件（.EOF 格式）列表。\n",
    "    这些轨道文件包含卫星的精确位置信息，用于 InSAR 数据处理中的几何校正和配准。\n",
    "    \n",
    "    Returns:\n",
    "        list[str]: 轨道文件名列表（.EOF 格式）。如果获取失败，返回空列表。\n",
    "    \"\"\"\n",
    "    url_root = \"https://s1qc.asf.alaska.edu/aux_poeorb\"\n",
    "\n",
    "    try:\n",
    "        session = _create_session()\n",
    "        response = session.get(url_root, timeout=30)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # print(response.text)\n",
    "        # Extract all .EOF files from the HTML\n",
    "        orbit_files = re.findall(r'href=\"([^\"]*\\.EOF)\"', response.text)\n",
    "        print(f\"Found {len(orbit_files)} orbit files.\")\n",
    "        return orbit_files\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to get orbit list: {e}\")\n",
    "        return []\n",
    "\n",
    "def _create_session() -> requests.Session:\n",
    "    \"\"\"\n",
    "    创建一个带有重试策略的 requests 会话。\n",
    "    \n",
    "    配置了自动重试机制，用于处理网络请求中的常见错误（如服务器错误、超时等），\n",
    "    提高下载轨道文件的可靠性。\n",
    "    \n",
    "    Returns:\n",
    "        requests.Session: 配置好重试策略的会话对象。\n",
    "    \"\"\"\n",
    "    session = requests.Session()\n",
    "\n",
    "    # Setup retry strategy\n",
    "    retry_strategy = Retry(\n",
    "        total=3,\n",
    "        backoff_factor=1,\n",
    "        status_forcelist=[429, 500, 502, 503, 504],\n",
    "    )\n",
    "\n",
    "    adapter = HTTPAdapter(max_retries=retry_strategy)\n",
    "    session.mount(\"http://\", adapter)\n",
    "    session.mount(\"https://\", adapter)\n",
    "\n",
    "    return session\n",
    "\n",
    "# Download Precise Orbit\n",
    "from datetime import datetime, timedelta\n",
    "orbit_list = _get_orbit_list()\n",
    "if not orbit_list:\n",
    "    print(\"Failed to get orbit file list from ASF server\")\n",
    "\n",
    "\n",
    "def _download_orbit_file_asf(orbit_file: str, output_path: os.PathLike) -> bool:\n",
    "    url_root = \"https://s1qc.asf.alaska.edu/aux_poeorb\"\n",
    "    file_url = f\"{url_root}/{orbit_file}\"\n",
    "\n",
    "    try:\n",
    "        session = _create_session()\n",
    "        response = session.get(file_url, stream=True, timeout=60)\n",
    "        response.raise_for_status()\n",
    "\n",
    "        # Get file size\n",
    "        total_size = int(response.headers.get('content-length', 0))\n",
    "        downloaded_size = 0\n",
    "\n",
    "        with open(output_path, 'wb') as file:\n",
    "            for chunk in response.iter_content(chunk_size=8192):\n",
    "                if chunk:\n",
    "                    file.write(chunk)\n",
    "                    downloaded_size += len(chunk)\n",
    "\n",
    "                    # Show progress\n",
    "                    if total_size > 0:\n",
    "                        progress = (downloaded_size / total_size) * 100\n",
    "                        print(f\"\\r  Progress: {progress:.1f}%\", end='', flush=True)\n",
    "\n",
    "        print()  # New line after progress\n",
    "        return True\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n  Download failed: {e}\")\n",
    "        # Clean up partially downloaded file\n",
    "        if output_path.exists():\n",
    "            output_path.unlink()\n",
    "        return False\n",
    "\n",
    "print(f\"Start downloading orbit files from ASF...\")\n",
    "# For each SAFE file, download the corresponding orbit file\n",
    "for safe_file in safe_files:\n",
    "    print(\"* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */\\n\")\n",
    "    print(f\"Processing: {os.path.basename(safe_file)}\")\n",
    "    \n",
    "    # Extract mission and timestamp from SAFE \n",
    "    basename = os.path.basename(safe_file)\n",
    "\n",
    "    # Remove .SAFE or .zip extension\n",
    "    if basename.endswith('.SAFE'):\n",
    "        basename = basename[:-5]\n",
    "    elif basename.endswith('.zip'):\n",
    "        basename = basename[:-4]\n",
    "\n",
    "    # Split by underscores\n",
    "    parts = basename.split('_')\n",
    "\n",
    "    if len(parts) < 6:\n",
    "        print(f\"  Invalid filename format: {basename}\")\n",
    "        continue\n",
    "\n",
    "    # Mission identifier (S1A or S1B)\n",
    "    mission = parts[0]\n",
    "\n",
    "    # Timestamps are typically at positions 5 and 6\n",
    "    # Format: YYYYMMDDTHHMMSS\n",
    "    start_time_str = parts[5]\n",
    "    stop_time_str = parts[6]\n",
    "\n",
    "    # Parse timestamps\n",
    "    try:\n",
    "        start_time = datetime.strptime(start_time_str, '%Y%m%dT%H%M%S')\n",
    "        stop_time = datetime.strptime(stop_time_str, '%Y%m%dT%H%M%S')\n",
    "    except ValueError:\n",
    "        print(f\"  Could not parse timestamps from: {basename}\")\n",
    "        continue\n",
    "\n",
    "    if not mission or not start_time:\n",
    "        print(\"  Could not parse SAFE filename, skipping\")\n",
    "        continue\n",
    "\n",
    "    # Calculate date range for orbit search (one day before and after)\n",
    "    date1 = (start_time - timedelta(days=1)).strftime('%Y%m%d')\n",
    "    date2 = (start_time + timedelta(days=1)).strftime('%Y%m%d')\n",
    "\n",
    "    # Find matching orbit file\n",
    "    mission_short = mission[-1]\n",
    "    # Search for matching orbit file\n",
    "    for orbit_file in orbit_list:\n",
    "    # Check if file matches mission and contains both dates\n",
    "        if (f\"S1{mission_short}\" in orbit_file and\n",
    "            date1 in orbit_file and date2 in orbit_file):\n",
    "            # Check if orbit file already exists in orbit directory\n",
    "            orbit_path = os.path.join(ORBIT_DIR, orbit_file)\n",
    "            if os.path.exists(orbit_path):\n",
    "                print(f\"  Orbit file already exists: {orbit_file}\")\n",
    "                continue\n",
    "            # Download orbit file\n",
    "            success = _download_orbit_file_asf(orbit_file, orbit_path)\n",
    "\n",
    "            if success:\n",
    "                print(f\"  Successfully downloaded: {orbit_file}\")\n",
    "            else:\n",
    "                print(f\"  Failed to download orbit file for: {os.path.basename(safe_file)}\")\n",
    "    \n",
    "print(\"* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */\\n\")\n",
    "print(f\"Finished downloading orbit files.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54859fee",
   "metadata": {},
   "source": [
    "<b>2. Download DEM</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "910fae7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preparing DEM ...\n",
      "* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */\n",
      "\n",
      "DEM_REGION: (47, 51, 7, 12)\n",
      "* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download DEM\n",
    "import zipfile\n",
    "# First, customize a function to detect the lat/lon region of the SLCs\n",
    "lon_list = []\n",
    "lat_list = []\n",
    "polygons = []\n",
    "print(f\"Start preparing DEM ...\")\n",
    "print(\"* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */\\n\")\n",
    "for safe_file in safe_files:\n",
    "    if safe_file.endswith(\".SAFE\"):\n",
    "        try:\n",
    "            # For unzipped SAFE files, find the KML file in the preview directory\n",
    "            kml_file = glob.glob(os.path.join(safe_file, \"preview\", f\"map-overlay.kml\"))\n",
    "            if kml_file:\n",
    "                with open(kml_file[0], 'r', encoding='utf-8') as kml:  # Fixed variable name and encoding\n",
    "                    content = kml.read()\n",
    "        except Exception as e:\n",
    "            raise IOError(f\"Error extracting KML from SAFE file {safe_file}: {e}\")\n",
    "        \n",
    "    elif safe_file.endswith(\".zip\"):\n",
    "        # For zipped SAFE files, directly read the KML file from inside the ZIP\n",
    "        try:\n",
    "            with zipfile.ZipFile(safe_file, 'r') as zip_ref:\n",
    "                # Search for the map-overlay.kml file in the preview directory\n",
    "                kml_entries = [entry for entry in zip_ref.namelist() if \"preview/map-overlay.kml\" in entry]\n",
    "                if kml_entries:\n",
    "                    # Read the KML content directly from the ZIP file\n",
    "                    with zip_ref.open(kml_entries[0]) as kml_file:\n",
    "                        content = kml_file.read().decode('utf-8', errors='ignore')\n",
    "        except Exception as e:\n",
    "            raise IOError(f\"Error processing ZIP file {safe_file}: {e}\")\n",
    "\n",
    "    coord_pattern = r'<coordinates[^>]*>(.*?)</coordinates>'\n",
    "    coord_matches = re.findall(coord_pattern, content, re.DOTALL | re.IGNORECASE)\n",
    "\n",
    "    for coord_block in coord_matches:\n",
    "        points = []\n",
    "        coord_text = coord_block.strip()\n",
    "        coord_text = re.sub(r'\\s+', ' ', coord_text)\n",
    "        coord_triplets = coord_text.split()\n",
    "\n",
    "        for coord_str in coord_triplets:\n",
    "            if ',' in coord_str:\n",
    "                parts = coord_str.split(',')\n",
    "                if len(parts) >= 2:\n",
    "                    try:\n",
    "                        lon = float(parts[0])\n",
    "                        lat = float(parts[1])\n",
    "                        if -180 <= lon <= 180 and -90 <= lat <= 90:\n",
    "                            points.append((lon, lat))\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "\n",
    "    if points:\n",
    "        # Remove duplicate closing point if exists\n",
    "        if len(points) > 1 and points[0] == points[-1]:\n",
    "            points = points[:-1]\n",
    "        polygons.append(points)\n",
    "    \n",
    "if polygons and len(polygons) > 0:\n",
    "    lons = [pt[0] for pt in polygons[0]]\n",
    "    lats = [pt[1] for pt in polygons[0]]\n",
    "    lon_list.extend(lon for lon in lons)\n",
    "    lat_list.extend(lat for lat in lats)\n",
    "\n",
    "# Find the common lat/lon region of the SLCs\n",
    "DEM_REGION = (int(min(lat_list)), int(max(lat_list)) + 1, int(min(lon_list)), int(max(lon_list)) + 1)\n",
    "print(f\"DEM_REGION: {DEM_REGION}\")\n",
    "print(\"* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f434b6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region: Latitude 51°N–47°N, Longitude 7°E–12°E\n",
      "DEM source: SRTM\n",
      "Directory: /mnt/e/DEM/SRTMGL1/ \n",
      "* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */\n",
      "\n",
      "Found 20 tiles:\n",
      "  N50E007.hgt\n",
      "  N50E008.hgt\n",
      "  N50E009.hgt\n",
      "  N50E010.hgt\n",
      "  N50E011.hgt\n",
      "  N49E007.hgt\n",
      "  N49E008.hgt\n",
      "  N49E009.hgt\n",
      "  N49E010.hgt\n",
      "  N49E011.hgt\n",
      "  N48E007.hgt\n",
      "  N48E008.hgt\n",
      "  N48E009.hgt\n",
      "  N48E010.hgt\n",
      "  N48E011.hgt\n",
      "  N47E007.hgt\n",
      "  N47E008.hgt\n",
      "  N47E009.hgt\n",
      "  N47E010.hgt\n",
      "  N47E011.hgt\n",
      "* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */\n",
      "\n",
      "Mosaicing 20 tiles into 4x5 grid\n",
      "Successfully mosaiced DEM with shape (14400, 18000)\n",
      "* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wang_xuanxuan/tools/miniforge/envs/opera/lib/python3.12/site-packages/osgeo/gdal.py:330: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved GeoTIFF: /mnt/e/InSAR/Stuttgart/ISCE3/DEM/demLat_N47_N51_Lon_E007_E012_orthometric.tif\n",
      "Generated ISCE2 XML metadata: /mnt/e/InSAR/Stuttgart/ISCE3/DEM/demLat_N47_N51_Lon_E007_E012.xml\n",
      "* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */\n",
      "\n",
      "Converting heights from EGM96 to WGS84 ellipsoidal heights\n"
     ]
    }
   ],
   "source": [
    "from mosaic_dem import prepare_dem_core\n",
    "dem_output_prefix = os.path.join(WORKSPACE, \"DEM\", f\"demLat_N{DEM_REGION[0]:02d}_N{DEM_REGION[1]:02d}_Lon_E{DEM_REGION[2]:03d}_E{DEM_REGION[3]:03d}\")\n",
    "os.makedirs(os.path.dirname(dem_output_prefix), exist_ok=True)\n",
    "os.chdir(LOCAL_DEM_DIR)\n",
    "prepare_dem_core(\n",
    "    bbox=DEM_REGION,\n",
    "    source=\"srtm\",\n",
    "    dem_dir=LOCAL_DEM_DIR,\n",
    "    local_only=True,\n",
    "    output=dem_output_prefix,\n",
    "    height=\"ellipsoidal\",\n",
    "    sample=\"3601\"\n",
    ")\n",
    "dem_output = dem_output_prefix + \".dem.wgs84\"\n",
    "print(\"* - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - */\\n\")\n",
    "print(f\"Finished downloading and mosaicing DEM - {dem_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea3ae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from update_cslc_config import main as update_cslc_config_main\n",
    "config_file = os.path.join(WORKSPACE, \"s1_cslc.yaml\")\n",
    "product_dir = os.path.join(WORKSPACE, \"PRODUCT\")\n",
    "scrath_dir = os.path.join(WORKSPACE, \"SCRATCH\")\n",
    "sas_output = os.path.join(product_dir, \"sas_output.json\")\n",
    "iargs = [config_file,\n",
    "         \"--safe-dir\", RAW_LOCATION, \n",
    "         \"--orbit-dir\", ORBIT_DIR, \n",
    "         \"--dem-file\", dem_output, \n",
    "         \"--product-path\", product_dir, \n",
    "         \"--scratch-path\", scrath_dir, \n",
    "         \"--sas-file\", sas_output, \n",
    "         '--gpu-enabled']   \n",
    "\n",
    "update_cslc_config_main(iargs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opera",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
